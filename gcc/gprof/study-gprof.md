study-gprof
===========

## 简介

gprof是一个用来统计可执行程序数据的工具。它能帮助用户确定程序在哪个地方耗时过多，以便优化程序。

gprof是GNU profile工具，可以运行于linux、AIX、Sun等操作系统,
进行C、C++、Pascal、Fortran程序的性能分析，用于程序的性能优化以及程序瓶颈问题的查找和解决。
通过分析应用程序运行时产生的“flat profile”，可以得到每个函数的调用次数，每个函数消耗的处理器时间，
也可以得到函数的“调用关系图”，包括函数调用的层次关系，每个函数调用花费了多少时间。

特点： 它只能分析应用程序在运行过程中所消耗掉的CPU时间，只有当应用程序的函数消耗CPU的时候，
gprof才能够获取函数的性能数据。如果应用程序在运行过程中暂时挂起，
并在系统内核唤醒应用程序后进一步执行，那么在应用程序中间暂停的时间性能数据是无法统计的；
而且在应用程序等待I/O操作返回的时间，性能数据也是无法统计的。

[gprof用户手册网站](http://sourceware.org/binutils/docs-2.17/gprof/index.html)

## 原理

在所有的函数内部加入了三个函数：

```txt
.cfi_startproc  负责初始化profile环境，分配内存空间
_mcount         记录每个函数代码的caller和callee的位置
.cfi_endproc清除profile环境，保存结果数据为gmon.out，供gprof分析结果
```

在编译和链接程序的时候（使用 -pg 编译和链接选项），
gcc 在你应用程序的每个函数中都加入了一个名为mcount（or“_mcount”, or“__mcount”）的函数，
也就是说-pg编译的应用程序里的每一个函数都会调用mcount,
而mcount会在内存中保存一张函数调用图，并通过函数调用堆栈的形式查找子函数和父函数的地址。
这张调用图也保存了所有与函数相关的调用时间，调用次数等等的所有信息。

程序运行结束后，会在程序退出的路径下生成一个 gmon.out文件。
这个文件就是记录并保存下来的监控数据。
可以通过命令行方式的gprof或图形化的Kprof来解读这些数据并对程序的性能进行分析。

## 功能

Gprof 是GNU gnu binutils工具之一，默认情况下linux系统当中都带有这个工具。

* 可以显示“flat profile”，包括每个函数的调用次数，每个函数消耗的处理器时间，
* 可以显示“Call graph”，包括函数的调用关系，每个函数调用花费了多少时间。
* 可以显示“注释的源代码”－－是程序源代码的一个复本，标记有程序中每行代码的执行次数。

gprof可以用来分析系统在运行时各函数调用的次数，耗时等情况，可以方便地帮助我们定位系统的瓶颈，
同时也能让我们知道对程序的那个位置进行优化能够带来尽可能大的性能提升。
gprof 优化尤其适用于CPU、内存密集性的应用模块。

## gprof使用

### 安装


### 使用步骤

* 编译程序加上`-pg`选项

  编译器会自动在目标代码中插入用于性能测试的代码片断，
  这些代码在程序运行时采集并记录函数的调用关系和调用次数，
  并记录函数自身执行时间和被调用函数的执行时间。

* 执行编译后的程序

  该步骤运行程序的时间会稍慢于正常编译的可执行程序的运行时间。
  程序运行结束后，会在程序所在路径下生成一个缺省文件名为gmon.out的文件，
  这个文件就是记录程序运行的性能、调用关系、调用次数等信息的数据文件。

* 使用`gprof`分析

  如：gprof test gmon.out则可以在显示器上看到函数调用相关的统计、分析信息。
  上述信息也可以采用`gprof test gmon.out > gprofresult.txt`重定向到文本文件以便于后续分析。

### 相关参数

选项        |  解释
------------|------------------------------------------------
-b          | 不再输出统计图表中每个字段的详细描述。
-p          | 只输出函数的调用图（Call graph的那部分信息）。
-q          | 只输出函数的时间消耗列表。
-e name     | 不再输出函数Name 及其子函数的调用图（除非它们有未被限制的其它父函数）。可以给定多个 -e 标志。一个 -e 标志只能指定一个函数。
-E name     | 不再输出函数Name 及其子函数的调用图，此标志类似于 -e 标志，但它在总时间和百分比时间的计算中排除了由函数Name 及其子函数所用的时间。
-f name     | 输出函数Name 及其子函数的调用图。可以指定多个 -f 标志。一个 -f 标志只能指定一个函数。
-F name     | 输出函数Name 及其子函数的调用图，它类似于 -f 标志，但它在总时间和百分比时间计算中仅使用所打印的例程的时间。可以指定多个 -F 标志。一个 -F 标志只能指定一个函数。-F 标志覆盖 -E 标志。
-z          | 显示使用次数为零的例程（按照调用计数和累积时间计算）。

## 数据分析

### flat profile模式

使用如下命令生成:

    $ gprof -p your_program gmoun.out

输出结果如下:

```txt
Flat profile:

Each sample counts as 0.01 seconds.
  %   cumulative   self              self     total           
 time   seconds   seconds    calls  ns/call  ns/call  name    
101.10      0.92     0.92  3000000   306.67   306.67  slow_multiply
  0.00      0.92     0.00  3000000     0.00     0.00  fast_multiply
```

各个参数的含义:

参数                | 解释
--------------------|-------------------------------------------------------------------
%time               | 函数以及衍生函数（函数内部再次调用的子函数）所占的总运行时间的百分比
cumulative seconds  | 函数累计执行的时间 (只是包括gprof能够监控到的函数)
self seconds        | 函数本身执行时间 (所有被调用次数的合共时间)
calls               | 函数的调用次数
selfms/call         | 函数平均执行时间 (函数的单次执行时间) (不包括被调用时间)
totalms/call        | 函数平均执行时间 (函数的单次执行时间) (包括被调用时间)
name                | 函数名称

### call graph模式

使用如下命令生成:

    $ gprof -p your_program gmoun.out

输出结果如下:

```txt
		     Call graph (explanation follows)


granularity: each sample hit covers 2 byte(s) for 1.09% of 0.92 seconds

index % time    self  children    called     name
                0.92    0.00 3000000/3000000     main [2]
[1]    100.0    0.92    0.00 3000000         slow_multiply [1]
-----------------------------------------------
                                                 <spontaneous>
[2]    100.0    0.00    0.92                 main [2]
                0.92    0.00 3000000/3000000     slow_multiply [1]
                0.00    0.00 3000000/3000000     fast_multiply [3]
-----------------------------------------------
                0.00    0.00 3000000/3000000     main [2]
[3]      0.0    0.00    0.00 3000000         fast_multiply [3]
-----------------------------------------------
```

> note: 按照调用时间排序，整个函数调用树被分为很多块。
每一个用横线包围起来的块是一个函数调用分支。在某个块中，左侧带有索引的是当前关注的函数，
其上方一行是调用它的函数，下方是它调用的函数。

各个参数的含义:

参数        | 解释
------------|-------------------------------------------------------------------
index       | 每个函数第一次出现时都分配了一个编号，根据编号可以方便的查找函数的具体分析数据
%           | 函数以及衍生函数（函数内部再次调用的子函数）所占的总运行时间的百分比
self        | 函数本身的执行时间
children    | 衍生函数执行的总时间
called      | 函数被调用的次数，不包括递归调用
name        | 函数名称

## 利用dot图形化

prof输出的格式报告，对于小规模的程序已经足够了，但是对于大规模的程序来说，就显得还是太繁杂了，
特别是我们把注意力放在调用关系上时，文本的跳跃总是让人不舒服。

把prof报告转换成图片，需要python和dot，还要下载gprof2dot.py的脚本。

### gprof2dot使用

* 下载地址

    https://github.com/jrfonseca/gprof2dot

* 相关参数

### 使用步骤

```sh
$ your_program                                      -- 产生gmon.out文件
$ gprof your_program gmon.out > result.log          -- 产生result.log文件
$ gprof2dot.py -n0 -e0 result.log > result.dot      -- 产生result.dot文件
$ dot -Tpng -o result.png result.dot                -- 产生result.png文件
```



## 使用局限

### 共享库支持

对于代码剖析的支持是由编译器增加的，因此如果要调试链接库，有以下两种方式:

* 对于用户库，在编译源码的时候加上`-pg`选项

* 对于系统库, 有些系统已经提供这样的库，如`libc.a`对应采用`-pg`编译的文件为`libc_p.a`，
              对于系统没有提供的库，就需要自己编译源码

> note: gprof目前还暂不支持对动态库中的函数进行性能分析

### 用户时间和内核时间

它只能分析应用程序在运行过程中所消耗掉的用户时间，无法得到程序内核空间的运行时间。
对内核态的调用分析无能为力。如果程序系统调用比率比较大，就不适合。

此外，时间是通过采样分析得到的，结果精度不高，如果执行时间很少，
那么可能采不到样，输出时，结果就忽略了，这也是很多地方看到的时间都是0.00的原因。

Gprof的特性使得有些程序非常难以进行优化，例如花费大部分时间睡眠等待内核唤醒的程序，
或者由于外部因素（例如操作系统的I/O子系统过载）而运行得非常慢的程序。

通常，有一个很好的基准测试可以用来查看gprof对于应用程序的优化能起多大作用，
方法是在time命令下面执行应用程序。此命令会显示一个应用程序运行完成需要多少时间，
并且在用户空间和内核空间各花费了多少时间。

```txt
例如：time./example 230
输出结果如下所示：
    real    2m30.295s
    user    0m0.000s
    sys     0m0.004s
```

我们可以看出应用程序整体运行150秒左右，但大部分时间在睡眠状态，
几乎没有多少时间被花费在执行用户空间和内核空间的代码上，
此时gprof的分析结果无法体现函数的实际运行时间。

### 多线程
gprof无法分析多线程程序。缘故是gprof使用`ITIMER_PROF`定时器，
当超时时由内核向应用程序发送信号。但多线程程序只有主线程接收`ITIMER_PROF`。

具体做法就是对`pthread_create`进行简单的包装(嵌入钩子), 并以动态库的形式在程序运行前加载。

可以参考[HOWTO: using gprof with multithreaded applications](http://sam.zoy.org/writings/programming/gprof.html)

实现例子，参考`demo/bounce.c`


### 多进程

如果用gprof分析多进程程序，则可能一个进程的gmon.out覆盖另一个进程的gmon.out，
解决方法是在执行程序之前执行：`export GMON_OUT_PREFIX=x.out`,
则之后生成的文件名就如x.out.pid，多进程的gmon.out就不会相互覆盖了。

从以上方法，衍生出一个测试平均值的方法：  
我们可以将几个gmon.out文件累加起来,然后用gprof来做整理的分析.

将gmon.out文件合起来做分析,如下:

```sh
$ gprof ./test gmon.out.*
```

### 程序退出

* 程序如果不是从main return或exit()退出，则可能不生成gmon.out。
* 程序如果崩溃，可能不生成gmon.out。
* 测试发现在虚拟机上运行，可能不生成gmon.out。
* 程序忽略SIGPROF信号！

> nore: 一定不能捕获、忽略SIGPROF信号。man手册对SIGPROF的解释是：`profiling timer expired`.
如果忽略这个信号，gprof的输出则是：`Each sample counts as 0.01 seconds. no time accumulated`.

下面提供一种测试程序不退出而要强制退出的方法：

```c
static void sighandler(int sig_no)
{
    exit(0);
}

signal(SIGUSR1, sighandler);
```

当使用kill -USR1 pid 后，程序退出，生成gmon.out文件。


## 常见的优化手段

关于具体的优化，这个可能就不是一点篇幅就能写得下了，提一些常见的经验供参考。

* for循环优化

  循环体内部节约n条指令，最终收益将乘以循环次数，这种优化是收益最高的一种优化之一。
  常见的如: 将循环体内不改变的变量移动到循环体外，多重循环嵌套时的顺序问题。

* 函数调用优化
  这是优化提高非常明显的一种方式，常见的方式如函数inline，这样可以节约大量的函数调用的开销，避免多次的压栈出栈。
  需要注意的是，在makefile中一定要指定-O优化，否则即使声明为inline函数，编译器也不会进行函数内联。

* 优化内存寻址,避免重复的内存寻址

* 优化cpu流水线的分支预测的成功率。

  比如，如果当前存在有 if～else if～else语句，将满足概率最高的条件放到靠前的位置不仅能减少判断和跳转指令的执行，还有利于cpu在流水作业时分支预测的成功率，提高指令的流水化。

> note: 3和4单独优化的提升不会很大，但是如果是在大量的循环体内部，提升就会被放大很多倍。


## 运用举例

### 使用Gprof 分析 Cflow开源项目

### 多线程

### 简单例子





